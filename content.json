{"meta":{"title":"夏天换上冬装的Blog","subtitle":"https://github.com/uniteReady/uniteReady.github.io","description":"夏天换上冬装的博客","author":"夏天换上冬装","url":"https://uniteready.github.io","root":"/"},"posts":[{"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://uniteready.github.io/tags/Javascript/"}],"title":"树形数据结构与扁平数据结构互转","date":"2019/12/19","text":"前言近日有需求做链路日志系统，从 elasticsearch 查询到的日志数据是扁平化结构，数据中包含层级关系的字段，前端按照层级展示。 所以需要对扁平数据做树形处理 数据源 下面是单条数据结构： { id: 1, pid: 0, name: '1/0'} id 为不重复索引值 pid 为父级 id 下面简单构造一个扁平数据结构数据源 let data = [ { id: 1, pid: 0, name: '1/0' }, { id: 2, pid: 1, name: '2/0' }, { id: 0, pid: -1, name: '0/-1' }, { id: 3, pid: 1, name: '3/1' }, { id: 4, pid: 3, name: '4/3' }, { id: 6, pid: 5, name: '6/5' }, { id: 5, pid: 0, name: '5/0' }, { id: 7, pid: 2, name: '7/2' }] 扁平数据结构=>树形数据结构 对于下面的使用方法，是有一个 bug 的，那就是数据源的根父节点(最外层的父节点)，必须在数据源的首个位置（索引为 0），所以在使用本方法时需要依据 id 做一次排序 // 先依据id做一次排序，确保根父节点，在数据源首位data.sort((a, b) => a.id - b.id)function flatToNested(data) { let temp = [], result = [] for (let i = 0; i < data.length; i++) { // 将当前item塞入temp中(因为这一步，所以需要对数据源做排序) temp[data[i].id] = data[i] // 判断temp中有没有当前item的父类 if (temp[data[i].pid]) { // 判断childrenn，不存在则赋值空数组 if (!temp[[data[i].pid]]['children']) { temp[[data[i].pid]]['children'] = [] } // 将当前item塞入父类children字段中 temp[[data[i].pid]]['children'].push(data[i]) } else { // 在temp中找不到父类，就将item塞入result中 result.push(data[i]) } } return result}flatToNested(data) 处理完的数据： let data = [ { id: 0, pid: -1, name: '0/-1', children: [ { id: 1, pid: 0, name: '1/0', children: [ { id: 2, pid: 1, name: '2/0', children: [ { id: 7, pid: 2, name: '7/2' } ] }, { id: 3, pid: 1, name: '3/1', children: [ { id: 4, pid: 3, name: '4/3' } ] } ] }, { id: 5, pid: 0, name: '5/0', children: [ { id: 6, pid: 5, name: '6/5' } ] } ] }] 树形数据结构=>扁平数据结构 目前的处理方法就是递归，因为不知道有多次层级，有新的想法请与我联系！ function NestedToFlat(data) { let result = [] for (let i = 0; i < data.length; i++) { result.push({ id: data[i]['id'], pid: data[i]['pid'], name: data[i]['name'] }) if (data[i]['children']) { result = result.concat(this.demo(data[i].children)) } } return result}","permalink":"https://uniteready.github.io/2019/12/19/%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84/","photos":[]},{"tags":[{"name":"hive","slug":"hive","permalink":"https://uniteready.github.io/tags/hive/"},{"name":"udf","slug":"udf","permalink":"https://uniteready.github.io/tags/udf/"}],"title":"UDFToTopN案例","date":"2018/06/30","text":"需求: 统计最热门的课程Top10http://bigdata.com/course/458655.html => 458655http://bigdata.com/course/458655/2.html?a=b&c=d => 458655_2解析后再统计课程Top10 1.使用 MockClassData生成数据package com.cj.bigdata.hive.hiveWork;import java.io.*;import java.util.Random;public class MockClassData { public static void main(String[] args) throws IOException { //课程号数组 String words[] = {\"123\",\"4354\",\"43541\",\"43542\",\"43543\",\"43544\",\"43545\",\"43546\",\"43547\",\"43548\"}; Random random = new Random(); //文件输出流对象 BufferedWriter bufferedWriter = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(new File(\"data/input/classData.txt\")))); //for循环随机生成数据 for (int i = 0; i < 30000; i++) { bufferedWriter.write(\"http://bigdata.com/course/\" + words[random.nextInt(words.length)]); if(random.nextInt(4) != 0){ bufferedWriter.write(\"/\" + random.nextInt(3) + \".html?a=b&c=d\"); bufferedWriter.newLine(); }else { bufferedWriter.write(\".html\"); bufferedWriter.newLine(); } } bufferedWriter.flush(); bufferedWriter.close(); }} 2.创建表CREATE TABLE `default.class`( `class_str` string) 3.将数据upload服务器并import到table classload data local inpath '/home/jackson/data/classData.txt' overwrite into table class;#检查数据select * from class limit 10; 4.编写UDFParseClassCodepackage com.cj.bigdata.hive.hiveWork;import org.apache.hadoop.hive.ql.exec.UDF;public class UDFParseClassCode extends UDF { /*** * * http://bigdata.com/course/4354/2.html?a=b&c=d * http://bigdata.com/course/43548.html */ public String evaluate(String str){ StringBuffer buffer = new StringBuffer(); String[] splits01 = str.split(\".html\"); //http://bigdata.com/course/4354/2或http://bigdata.com/course/43548 String splits02 = splits01[0]; String[] splits03 = splits02.split(\"/\"); //用split后的的最后一块的长度来判断是//http://bigdata.com/course/4354/2还是http://bigdata.com/course/43548 if(splits03[splits03.length - 1].length() == 1){ buffer.append(splits03[splits03.length - 2]); buffer.append(\"_\"); buffer.append(splits03[splits03.length - 1]); }else { buffer.append(splits03[splits03.length - 1]); } return buffer.toString(); }} 5.打包上传生成UDF函数执行sql5.1上传到$HIVE_HOME/auxlibCREATE TEMPORARY FUNCTION parseClass AS 'com.cj.bigdata.hive.hiveWork.UDFParseClassCode'; 5.2sql完成需求select parseClass(class_str) class_code, count(*) topNfrom class group by parseClass(class_str) limit 10 ; 结果： class_code topN123 801123_0 759123_1 773123_2 74943547 1843541 72143541_0 72843541_1 75943541_2 75443542 728","permalink":"https://uniteready.github.io/2018/06/30/UDFToTopN%E6%A1%88%E4%BE%8B/","photos":[]},{"tags":[{"name":"hive","slug":"hive","permalink":"https://uniteready.github.io/tags/hive/"}],"title":"hive_sql案例（实现窗口功能）","date":"2018/06/25","text":"1.需求domain time trafficgifshow.com 2020/01/01 5yy.com 2020/01/01 4huya.com 2020/01/01 1gifshow.com 2020/01/20 6gifshow.com 2020/02/01 8yy.com 2020/01/20 5gifshow.com 2020/02/02 7==>domain 月份 小计 累计gifshow.com 2020-01 11 11gifshow.com 2020-02 15 26yy.com 2020-01 9 9huya.com 2020-01 1 1 2.需求实现2.1创建表create table domain_traffic(domain string,time string,traffic string) row format delimited fields terminated by ','; 2.2处理数据gifshow.com,2020-01-01,5yy.com,2020-01-01,4huya.com,2020-01-01,1gifshow.com,2020-01-20,6gifshow.com,2020-02-01,8yy.com,2020-01-20,5gifshow.com,2020-02-02,7 2.3load dataload data local inpath '/home/jackson/data/domainData.txt' overwrite into table domain_traffic; 2.4数据和期望结果数据huya.com 2020-01-01 1gifshow.com 2020-01-20 6gifshow.com 2020-02-01 8yy.com 2020-01-20 5gifshow.com 2020-02-02 7 期望结果domain 月份 小计 累计gifshow.com 2020-01 11 11gifshow.com 2020-02 15 26yy.com 2020-01 9 9huya.com 2020-01 1 1 2.5sql分步实现**************tempselect domain, date_format(time,'yyyy-MM'), sum(traffic)from domain_traffic group by domain,date_format(time,'yyyy-MM'); gifshow.com 2020-01 11.0gifshow.com 2020-02 15.0huya.com 2020-01 1.0yy.com 2020-01 9.0**************selecta.*,b.*from temp a join temp b on a.domain=b.domain temp2 selecta.*,b.*from (select domain, date_format(time,'yyyy-MM') time, sum(traffic) pv from domain_traffic group by domain,date_format(time,'yyyy-MM')) a join (select domain, date_format(time,'yyyy-MM') time, sum(traffic) pv from domain_traffic group by domain,date_format(time,'yyyy-MM')) b on a.domain=b.domain temp2 gifshow.com 2020-01 11.0 gifshow.com 2020-01 11.0gifshow.com 2020-01 11.0 gifshow.com 2020-02 15.0gifshow.com 2020-02 15.0 gifshow.com 2020-01 11.0gifshow.com 2020-02 15.0 gifshow.com 2020-02 15.0huya.com 2020-01 1.0 huya.com 2020-01 1.0yy.com 2020-01 9.0 yy.com 2020-01 9.0***********1月要的数据：1月自身的2..........: 1月和2月的select a.domain, a.time, a.pv, sum(b.pv)from temp2 where a.time >= b.time group by a.domain,a.time,a.pv select a.domain, a.time, a.pv, sum(b.pv)from (select domain,date_format(time,'yyyy-MM') time,sum(traffic) pv from domain_traffic group by domain,date_format(time,'yyyy-MM')) a join (select domain,date_format(time,'yyyy-MM') time,sum(traffic) pv from domain_traffic group by domain,date_format(time,'yyyy-MM')) b on a.domain=b.domain where a.time >= b.time group by a.domain,a.time,a.pv 等同于 with t as(select domain,date_format(time,'yyyy-MM') time,sum(traffic) pv from domain_traffic group by domain,date_format(time,'yyyy-MM'))select a.domain, a.time, a.pv, sum(b.pv)from t a join t bon a.domain=b.domain where a.time >= b.time group by a.domain,a.time,a.pv 最终结果: gifshow.com 2020-01 11.0 11.0gifshow.com 2020-02 15.0 26.0huya.com 2020-01 1.0 1.0yy.com 2020-01 9.0 9.0","permalink":"https://uniteready.github.io/2018/06/25/hive_sql%E6%A1%88%E4%BE%8B(%E5%AE%9E%E7%8E%B0%E7%AA%97%E5%8F%A3%E5%8A%9F%E8%83%BD)/","photos":[]},{"tags":[{"name":"linux","slug":"linux","permalink":"https://uniteready.github.io/tags/linux/"}],"title":"大数据Linux常用命令1","date":"2017/06/30","text":"1. 命令行头[root@node1 ~]#root 默认管理员 最大权限node1 机器名称~ 当前该用户的 家目录 /root 2. pwd 查看当前光标所在的目录 路径[root@node1 ~]# pwd/root 3. ls 查看ls 显示文件夹 文件名称ls -l 显示额外信息 权限 用户用户组 时间 大小ls -l -a 也显示隐藏文件夹 文件[root@node1 ~]# ls -l -atotal 40dr-xr-x---. 6 root root 4096 Apr 15 21:51 .dr-xr-xr-x. 17 root root 4096 Aug 8 2018 ..-rw-------. 1 root root 3814 Apr 15 21:49 .bash_history-rw-r--r--. 1 root root 18 Dec 29 2013 .bash_logout隐藏文件夹 文件是以.开头ls -l -h 仅仅查看文件的大小ls -l -r -t 按时间排序如何快速找到哪些文件 更新了ls -l ==》ll 等价ll -all -rtll -h 4.mkdir 创建文件夹[root@node1 ~]# mkdir bigdata[root@node1 ~]# [root@node1 ~]# lsbigdata[root@node1 ~]#mkdir dir1 dir2 dir3 并mkdir -p dir4/dir5/dir6 串 级联创建 5. cd 切换目录 路径[root@node1 ~]# cd /Linux系统 从根目录 标识 /cd dir1 进入dir1文件夹cd ../ 退上一层目录cd ../../ 2层root用户 家目录 /root普通xx用户 家目录 /home/xx家目录 是 ~ 表示 如何进家目录:cd /rootcd 直接回车 cd ~cd - 回退到上一次的目录[root@node1 ~]# cd dir4[root@node1 dir4]# cd dir5/dir6[root@node1 dir6]# [root@node1 dir6]# cd -/root/dir4[root@node1 dir4]# 6. 命令帮助 help[root@node1 /]# ls --helpUsage: ls [OPTION]... [FILE]...[]标识的 可选... 多个参数Usage: ls [OPTIONS]Usage: ls XXX [OPTIONS]List information about the FILEs (the current directory by default).Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.Mandatory arguments to long options are mandatory for short options too.-a, --all do not ignore entries starting with .-A, --almost-all do not list implied . and ..","permalink":"https://uniteready.github.io/2017/06/30/%E5%A4%A7%E6%95%B0%E6%8D%AELinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A41/","photos":[]}],"categories":[],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://uniteready.github.io/tags/Javascript/"},{"name":"hive","slug":"hive","permalink":"https://uniteready.github.io/tags/hive/"},{"name":"udf","slug":"udf","permalink":"https://uniteready.github.io/tags/udf/"},{"name":"linux","slug":"linux","permalink":"https://uniteready.github.io/tags/linux/"}]}